# K-Nearest Neighbors (KNN) Classification - Iris Dataset

## ðŸ“Œ Overview
This project demonstrates the implementation of the **K-Nearest Neighbors (KNN)** algorithm for classification problems using the **Iris dataset**.

The project:
- Extracts dataset from a ZIP file
- Normalizes features
- Trains KNN models with multiple K values
- Evaluates performance using accuracy, confusion matrix, and classification report
- Visualizes decision boundaries for better understanding

---

## ðŸ›  Tools & Libraries
- Python 3.x
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Seaborn

---

## ðŸ“‚ Dataset
The dataset used is **Iris.csv** inside `archive.zip`.

Columns:
- SepalLengthCm
- SepalWidthCm
- PetalLengthCm
- PetalWidthCm
- Species (Target)

---

## ðŸš€ Steps to Run
1. Upload the `archive.zip` file containing `Iris.csv` to the environment (e.g., Google Colab).
2. Open and run the `KNN_Classification.ipynb` notebook.
3. The notebook will:
   - Extract CSV from ZIP
   - Normalize features
   - Train & evaluate KNN model
   - Display confusion matrix & decision boundary plot directly in the notebook

---

## ðŸ“Š Results
- **Accuracy**: Achieved high accuracy (>95%) with the best K value
- **Confusion Matrix**: Shows correct classification distribution
- **Decision Boundary**: Graphical representation of KNN's classification zones

---

## ðŸ“œ License
This project is open-source and available under the MIT License.
